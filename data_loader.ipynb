{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import datetime\n",
    "from time import sleep\n",
    "import os\n",
    "from os import listdir as ls\n",
    "from tqdm import tqdm\n",
    "import pytz\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, transform\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensor\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "plt.ion()\n",
    "%load_ext tensorboard\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kill 78340"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_log_dir = '.././logs/tensorboard/train/2019-05-21_15-05'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_log_dir = os.path.join(\".././logs/tensorboard/train/\",\n",
    "                                datetime.datetime.now(tz=pytz.timezone('Europe/Moscow')).strftime(\"%Y-%m-%d_%H-%M\"))\n",
    "print('nohup tensorboard --logdir='+train_log_dir+' &')\n",
    "os.makedirs(train_log_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_summary_writer = SummaryWriter(train_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_example(example):\n",
    "    \"\"\"\n",
    "    Show image with labels\n",
    "    Args:\n",
    "    example: dict or image(ndarray)\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    if isinstance(example, dict):\n",
    "        image = example['image']\n",
    "        plt.title(str(example['labels']))\n",
    "    else:\n",
    "        image = example\n",
    "    plt.imshow(image)\n",
    "    plt.show()  \n",
    "    \n",
    "\n",
    "def show_batch(sample_batched):\n",
    "    \"\"\"Show image with landmarks for a batch of samples.\"\"\"\n",
    "    images_batch, labels_batch = \\\n",
    "            sample_batched['image'], sample_batched['labels']\n",
    "    batch_size = len(images_batch)\n",
    "    im_size = images_batch.size(2)\n",
    "    print('Batch shape', images_batch.size())\n",
    "\n",
    "    grid = utils.make_grid(images_batch)\n",
    "    plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
    "    plt.title('Batch from dataloader')\n",
    "    \n",
    "\n",
    "def show_train_batches(dataloader, i):\n",
    "    for i_batch, sample_batched in enumerate(dataloader):\n",
    "        print(i_batch, sample_batched['image'].size(),\n",
    "              sample_batched['labels'].size())\n",
    "\n",
    "        if i_batch == i:\n",
    "            plt.figure()\n",
    "            show_batch(sample_batched)\n",
    "            plt.axis('off')\n",
    "            plt.ioff()\n",
    "            plt.show()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChestnetDataset(Dataset):\n",
    "    \"\"\"Chest X-ray picture dataset annotated with patologies\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.df.iloc[idx, 0])\n",
    "        image = cv2.imread(img_name)\n",
    "        # By default OpenCV uses BGR color space for color images,\n",
    "        # so we need to convert the image to RGB color space.\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        labels = self.df.iloc[idx, 1:-1].values.astype(int)\n",
    "        sample = {'image': image, 'labels': labels}\n",
    "\n",
    "        if self.transform:\n",
    "            # Apply tranform to numpy.ndarray which represents sample image\n",
    "            augmented = self.transform(image=sample['image'])\n",
    "            sample['image'] = augmented['image']\n",
    "            sample['labels'] = torch.from_numpy(sample['labels']).float()\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    A.HorizontalFlip(),\n",
    "    A.Rotate(limit=30),\n",
    "    A.RandomBrightnessContrast(brightness_limit = 0.1, contrast_limit = 0.1),\n",
    "    A.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "    ),\n",
    "    ToTensor()\n",
    "])\n",
    "val_transform = A.Compose([ \n",
    "    A.Resize(256, 256),\n",
    "    A.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "    ),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "        \n",
    "fold_titles = [('fold1234', 'fold0'),('fold0234', 'fold1'),('fold0134', 'fold2'),('fold0124', 'fold3'),('fold0123', 'fold4')]\n",
    "folds = dict() # {'fold0': (train_dl0, val_dl0),...,'fold4' : (train_dl4, val_dl4)}\n",
    "for train, val in fold_titles:\n",
    "    print(train, val)\n",
    "    train_dataset = ChestnetDataset(os.path.join('../dataset/', train+'.csv'), \n",
    "                                    '../../../datasets/ilyas/ChestNets/images/',\n",
    "                                    transform=train_transform)\n",
    "    val_dataset = ChestnetDataset(os.path.join('../dataset/', val+'.csv'), \n",
    "                                  '../../../datasets/ilyas/ChestNets/images/',\n",
    "                                  transform=val_transform)\n",
    "\n",
    "    train_dl = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=8)\n",
    "    val_dl = DataLoader(val_dataset, batch_size=32, shuffle=True, num_workers=8)\n",
    "    folds[val] = (train_dl, val_dl)\n",
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import re\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def new_densenet121(imagenet=True, path_to_weights=None):\n",
    "    net = torchvision.models.densenet121()\n",
    "    if imagenet:        \n",
    "        state_dict = torch.load('../weights/misc/densenet121_pretrained.pth')\n",
    "        # '.'s are no longer allowed in module names, but pervious _DenseLayer\n",
    "        # has keys 'norm.1', 'relu.1', 'conv.1', 'norm.2', 'relu.2', 'conv.2'.\n",
    "        # They are also in the checkpoints in model_urls. This pattern is used\n",
    "        # to find such keys.\n",
    "        pattern = re.compile(\n",
    "            r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\n",
    "        for key in list(state_dict.keys()):\n",
    "            res = pattern.match(key)\n",
    "            if res:\n",
    "                new_key = res.group(1) + res.group(2)\n",
    "                state_dict[new_key] = state_dict[key]\n",
    "                del state_dict[key] \n",
    "        net.load_state_dict(state_dict)\n",
    "        num_ftrs = net.classifier.in_features\n",
    "        net.classifier = nn.Linear(num_ftrs, 14)\n",
    "    else:\n",
    "        if path_to_weights == None:\n",
    "            num_ftrs = net.classifier.in_features\n",
    "            net.classifier = nn.Linear(num_ftrs, 14)\n",
    "        else:\n",
    "            state_dict = torch.load(path_to_weights)\n",
    "            num_ftrs = net.classifier.in_features\n",
    "            net.classifier = nn.Linear(num_ftrs, 14)\n",
    "            net.load_state_dict(state_dict)\n",
    "    return net.to(device);\n",
    "\n",
    "\n",
    "def new_inceptionV3(imagenet=True, path_to_weights=None):\n",
    "    net = torchvision.models.inception_v3()\n",
    "    if imagenet:        \n",
    "        state_dict = torch.load('../weights/misc/inception_v3_pretrained_imagenet.pth')\n",
    "        # '.'s are no longer allowed in module names, but pervious _DenseLayer\n",
    "        # has keys 'norm.1', 'relu.1', 'conv.1', 'norm.2', 'relu.2', 'conv.2'.\n",
    "        # They are also in the checkpoints in model_urls. This pattern is used\n",
    "        # to find such keys.\n",
    "        pattern = re.compile(\n",
    "            r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\n",
    "        for key in list(state_dict.keys()):\n",
    "            res = pattern.match(key)\n",
    "            if res:\n",
    "                new_key = res.group(1) + res.group(2)\n",
    "                state_dict[new_key] = state_dict[key]\n",
    "                del state_dict[key] \n",
    "        net.load_state_dict(state_dict)\n",
    "        num_ftrs = net.fc.in_features\n",
    "        net.fc = nn.Linear(num_ftrs, 14)\n",
    "    else:\n",
    "        if path_to_weights == None:\n",
    "            num_ftrs = net.fc.in_features\n",
    "            net.fc = nn.Linear(num_ftrs, 14)\n",
    "        else:\n",
    "            state_dict = torch.load(path_to_weights)\n",
    "            num_ftrs = net.fc.in_features\n",
    "            net.fc = nn.Linear(num_ftrs, 14)\n",
    "            net.load_state_dict(state_dict)\n",
    "    net.aux_logits = False\n",
    "    return net.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_training_epoch(model, criterion, optimizer, scheduler=None):\n",
    "    model.train()\n",
    "    train_average_loss = 0.0\n",
    "    for i, data in enumerate(train_dl, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data['image'].to(device), data['labels'].to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_average_loss += loss.item()\n",
    "    train_average_loss /= len(train_dl)\n",
    "    return train_average_loss\n",
    "\n",
    "def compute_validation_loss(model, criterion):\n",
    "    model.eval()\n",
    "    val_average_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_dl, 0):\n",
    "            inputs, labels = data['image'].to(device), data['labels'].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_average_loss += loss.item()\n",
    "    val_average_loss /= len(val_dl)\n",
    "    return val_average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, val_criterion, optimizer, train_dl, val_dl, save_title='test', num_epochs=30):\n",
    "    \n",
    "    for epoch in tqdm(range(num_epochs)):  \n",
    "        train_average_loss = perform_training_epoch(model, criterion, optimizer)\n",
    "        val_average_loss = compute_validation_loss(model, val_criterion)\n",
    "        \n",
    "        train_summary_writer.add_scalar('train_loss '+save_title, train_average_loss, global_step = epoch)\n",
    "        train_summary_writer.add_scalar('val_loss '+save_title, val_average_loss, global_step = epoch)\n",
    "        train_summary_writer.close()\n",
    "        \n",
    "        torch.save(model.state_dict(), '../weights/inceptionV3_BCELoss_'+save_title+'_epoch'+str(epoch)+'.pth')\n",
    "        print(save_title+' [%d] train_loss: %.3f; val_loss: %.3f' % (epoch + 1, train_average_loss, val_average_loss))\n",
    "    \n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, logits=False, reduce=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.logits = logits\n",
    "        self.reduce = reduce\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        if self.logits:\n",
    "            BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduce=False)\n",
    "        else:\n",
    "            BCE_loss = F.binary_cross_entropy(inputs, targets, reduce=False)\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduce:\n",
    "            return torch.mean(F_loss)\n",
    "        else:\n",
    "            return F_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = {key: new_densenet121(imagenet = False, path_to_weights = model_weights[key]) for key in folds.keys()}\n",
    "models = {key: new_inceptionV3(imagenet = True) for key in folds.keys()}\n",
    "for key, (train_dl, val_dl) in folds.items():\n",
    "    print(key, train_dl, val_dl)\n",
    "    model = models[key]\n",
    "    val_criterion = nn.BCEWithLogitsLoss()\n",
    "#     criterion = nn.BCEWithLogitsLoss()\n",
    "    criterion = FocalLoss(logits= True)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    train(model, criterion, val_criterion, optimizer, train_dl, val_dl, save_title=key, num_epochs=40 )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.special import expit\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# K-fold validation. \n",
    "# Training models for each fold\n",
    "# Learning curves: logs.txt\n",
    "model_weights = {\n",
    "    'fold0': '../weights/inceptionV3_BCE_40epochs/inceptionV3_BCELoss_fold0_epoch17.pth',\n",
    "    'fold1': '../weights/inceptionV3_BCE_40epochs/inceptionV3_BCELoss_fold1_epoch39.pth',\n",
    "    'fold2': '../weights/inceptionV3_BCE_40epochs/inceptionV3_BCELoss_fold2_epoch39.pth',\n",
    "    'fold3': '../weights/inceptionV3_BCE_40epochs/inceptionV3_BCELoss_fold3_epoch39.pth',\n",
    "    'fold4': '../weights/inceptionV3_BCE_40epochs/inceptionV3_BCELoss_fold4_epoch19.pth'\n",
    "}\n",
    "dir = '../weights/inceptionV3_FocalLoss_40epochs'\n",
    "l = ls(dir)\n",
    "l = sorted(l)[1:-1]\n",
    "model_weights = {'fold{}'.format(i): os.path.join(dir,path) for i,path in enumerate(l)}\n",
    "model_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_dl):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_dl, 0):\n",
    "            inputs, labels = data['image'].to(device), data['labels'].to(device)\n",
    "            outputs = model(inputs).cpu()\n",
    "            outputs = expit(outputs)            \n",
    "            labels = labels.byte().cpu()\n",
    "            if i == 0: \n",
    "                all_labels = labels.numpy()\n",
    "                all_outputs = outputs.numpy()\n",
    "            else:\n",
    "                all_labels = np.vstack([all_labels, labels])\n",
    "                all_outputs = np.vstack([all_outputs, outputs])\n",
    "    auc_roc_per_class = dict()\n",
    "    for i in range(14):\n",
    "        x = all_outputs[:, i]\n",
    "        y = all_labels[:, i]\n",
    "        auc_roc_per_class[i] = roc_auc_score(y,x)\n",
    "    print(all_labels.shape, all_outputs.shape)\n",
    "    pprint(auc_roc_per_class)\n",
    "    return auc_roc_per_class\n",
    "\n",
    "def test_all_folds(models, save_dir):\n",
    "    test_dataset = ChestnetDataset(os.path.join('../dataset/test.csv'), \n",
    "                                  '../../../datasets/ilyas/ChestNets/images/',\n",
    "                                  transform=val_transform)\n",
    "    test_dl = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=8)\n",
    "    pathologies = ['Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule', 'Pneumonia', 'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia']\n",
    "    df = pd.DataFrame(pathologies,columns=['Class'])\n",
    "    for key, model in tqdm(models.items()):\n",
    "        df[key] = test_model(model, test_dl).values()\n",
    "    df.loc['Mean'] = df.mean()\n",
    "    df.loc['Mean', 'Class'] = 'Mean'\n",
    "    df['Mean'] = df.mean(axis=1)\n",
    "    df.to_csv(save_dir, index = False)\n",
    "    return df\n",
    "\n",
    "models = {key: new_inceptionV3(imagenet = False, path_to_weights=path) for key, path in model_weights.items()}\n",
    "test_all_folds(models,'../dataset/outputs/inceptionV3_FocalLoss_40epochs/InceptionV3_FocaLoss_AUCROC.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline():\n",
    "    test_dataset = ChestnetDataset(os.path.join('../dataset/test.csv'), \n",
    "                                  '../../../datasets/ilyas/ChestNets/images/',\n",
    "                                  transform=val_transform)\n",
    "    test_dl = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=8)\n",
    "    models = [new_densenet121() for _ in range(5)]\n",
    "    weights = {0: '../weights/densenet_fold0_epoch22.pth',\n",
    "              1: '../weights/densenet_fold1_epoch29.pth',\n",
    "              2: '../weights/densenet_fold2_epoch29.pth',\n",
    "              3: '../weights/densenet_fold3_epoch28.pth',\n",
    "              4: '../weights/densenet_fold4_epoch18.pth'}\n",
    "    for i, m in tqdm(enumerate(models,0)):\n",
    "        m.load_state_dict(torch.load(weights[i]))\n",
    "        m.eval()\n",
    "    \n",
    "    for i, data in tqdm(enumerate(test_dl, 0)):\n",
    "        outputs = {}\n",
    "        inputs, labels = data['image'].to(device), data['labels'].to(device)\n",
    "        \n",
    "#         Average Ensemble\n",
    "        for j, m in enumerate(models,0):\n",
    "            with torch.no_grad():\n",
    "                outputs[j] = expit(m(inputs).cpu()) \n",
    "        outputs = [out.numpy() for out in list(outputs.values())]    \n",
    "#         outputs = np.mean(outputs, axis=0)\n",
    "        \n",
    "        labels = labels.byte().cpu().numpy()\n",
    "\n",
    "        if i == 0: \n",
    "            all_outputs = {}\n",
    "            for j, out in enumerate(outputs,0):\n",
    "                all_outputs[j] = out\n",
    "            all_labels = labels\n",
    "#             all_outputs = outputs\n",
    "        else:\n",
    "            all_labels = np.vstack([all_labels, labels])\n",
    "            for j, out in enumerate(outputs,0):\n",
    "                all_outputs[j] = np.vstack([all_outputs[j], out])\n",
    "#             all_outputs = np.vstack([all_outputs, outputs])\n",
    "    \n",
    "       \n",
    "#     auc_roc_per_class = dict()\n",
    "#     for i in range(14):\n",
    "#         x = all_outputs[:, i]\n",
    "#         y = all_labels[:, i]\n",
    "#         auc_roc_per_class[i] = roc_auc_score(y,x)\n",
    "#     pprint(auc_roc_per_class)\n",
    "    return all_outputs\n",
    "out = baseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prediction_on_test(models, save_dir):\n",
    "    test_dataset = ChestnetDataset(os.path.join('../dataset/test.csv'), \n",
    "                                  '../../../datasets/ilyas/ChestNets/images/',\n",
    "                                  transform=val_transform)\n",
    "    test_dl = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=8)\n",
    "    for i, data in tqdm(enumerate(test_dl, 0)):\n",
    "        outputs = {}\n",
    "        inputs, labels = data['image'].to(device), data['labels'].to(device)\n",
    "        for j, m in enumerate(models.values(),0):\n",
    "            with torch.no_grad():\n",
    "                outputs[j] = expit(m(inputs).cpu()) \n",
    "        outputs = [out.numpy() for out in list(outputs.values())]\n",
    "        labels = labels.byte().cpu().numpy()\n",
    "        if i == 0: \n",
    "            all_outputs = {}\n",
    "            for j, out in enumerate(outputs,0):\n",
    "                all_outputs[j] = out\n",
    "            all_labels = labels\n",
    "        else:\n",
    "            all_labels = np.vstack([all_labels, labels])\n",
    "            for j, out in enumerate(outputs,0):\n",
    "                all_outputs[j] = np.vstack([all_outputs[j], out])\n",
    "    for i, output in enumerate(all_outputs.values()):\n",
    "        pd.DataFrame(output).to_csv('buffer.csv', index = False)\n",
    "        pd.DataFrame(output).to_csv(os.path.join(save_dir, 'fold{}_test.csv').format(i), index = False)\n",
    "    return all_outputs\n",
    "save_prediction_on_test(models, '../dataset/outputs/inceptionV3_FocalLoss_40epochs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0 vs 1</th>\n",
       "      <td>0.519554</td>\n",
       "      <td>0.462886</td>\n",
       "      <td>0.595989</td>\n",
       "      <td>0.455916</td>\n",
       "      <td>0.508987</td>\n",
       "      <td>0.437295</td>\n",
       "      <td>0.385088</td>\n",
       "      <td>0.478070</td>\n",
       "      <td>0.458332</td>\n",
       "      <td>0.464174</td>\n",
       "      <td>0.491516</td>\n",
       "      <td>0.332827</td>\n",
       "      <td>0.437981</td>\n",
       "      <td>0.405140</td>\n",
       "      <td>0.459554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0 vs 2</th>\n",
       "      <td>0.517262</td>\n",
       "      <td>0.466954</td>\n",
       "      <td>0.614793</td>\n",
       "      <td>0.505941</td>\n",
       "      <td>0.482850</td>\n",
       "      <td>0.418632</td>\n",
       "      <td>0.360367</td>\n",
       "      <td>0.455240</td>\n",
       "      <td>0.448881</td>\n",
       "      <td>0.494417</td>\n",
       "      <td>0.486628</td>\n",
       "      <td>0.301431</td>\n",
       "      <td>0.418792</td>\n",
       "      <td>0.363073</td>\n",
       "      <td>0.452519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0 vs 3</th>\n",
       "      <td>0.529353</td>\n",
       "      <td>0.465469</td>\n",
       "      <td>0.615186</td>\n",
       "      <td>0.488525</td>\n",
       "      <td>0.510776</td>\n",
       "      <td>0.451548</td>\n",
       "      <td>0.380558</td>\n",
       "      <td>0.511770</td>\n",
       "      <td>0.471389</td>\n",
       "      <td>0.476813</td>\n",
       "      <td>0.471540</td>\n",
       "      <td>0.359428</td>\n",
       "      <td>0.444039</td>\n",
       "      <td>0.377355</td>\n",
       "      <td>0.468125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0 vs 4</th>\n",
       "      <td>0.501555</td>\n",
       "      <td>0.461180</td>\n",
       "      <td>0.612255</td>\n",
       "      <td>0.477740</td>\n",
       "      <td>0.470529</td>\n",
       "      <td>0.403346</td>\n",
       "      <td>0.366094</td>\n",
       "      <td>0.460177</td>\n",
       "      <td>0.436334</td>\n",
       "      <td>0.485916</td>\n",
       "      <td>0.458933</td>\n",
       "      <td>0.343896</td>\n",
       "      <td>0.442039</td>\n",
       "      <td>0.277360</td>\n",
       "      <td>0.442668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1 vs 2</th>\n",
       "      <td>0.534864</td>\n",
       "      <td>0.496664</td>\n",
       "      <td>0.618571</td>\n",
       "      <td>0.477283</td>\n",
       "      <td>0.512987</td>\n",
       "      <td>0.435789</td>\n",
       "      <td>0.416289</td>\n",
       "      <td>0.460714</td>\n",
       "      <td>0.480073</td>\n",
       "      <td>0.489167</td>\n",
       "      <td>0.483012</td>\n",
       "      <td>0.351819</td>\n",
       "      <td>0.434470</td>\n",
       "      <td>0.449716</td>\n",
       "      <td>0.474387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1 vs 3</th>\n",
       "      <td>0.534862</td>\n",
       "      <td>0.459619</td>\n",
       "      <td>0.605366</td>\n",
       "      <td>0.457003</td>\n",
       "      <td>0.505878</td>\n",
       "      <td>0.478589</td>\n",
       "      <td>0.395858</td>\n",
       "      <td>0.492306</td>\n",
       "      <td>0.475342</td>\n",
       "      <td>0.472882</td>\n",
       "      <td>0.469717</td>\n",
       "      <td>0.356553</td>\n",
       "      <td>0.433657</td>\n",
       "      <td>0.487613</td>\n",
       "      <td>0.473232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1 vs 4</th>\n",
       "      <td>0.517859</td>\n",
       "      <td>0.428197</td>\n",
       "      <td>0.615715</td>\n",
       "      <td>0.431304</td>\n",
       "      <td>0.460887</td>\n",
       "      <td>0.390210</td>\n",
       "      <td>0.410461</td>\n",
       "      <td>0.450347</td>\n",
       "      <td>0.452135</td>\n",
       "      <td>0.491847</td>\n",
       "      <td>0.456821</td>\n",
       "      <td>0.344011</td>\n",
       "      <td>0.437947</td>\n",
       "      <td>0.305222</td>\n",
       "      <td>0.442354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 vs 3</th>\n",
       "      <td>0.528846</td>\n",
       "      <td>0.492057</td>\n",
       "      <td>0.638946</td>\n",
       "      <td>0.491296</td>\n",
       "      <td>0.489440</td>\n",
       "      <td>0.452739</td>\n",
       "      <td>0.391141</td>\n",
       "      <td>0.487755</td>\n",
       "      <td>0.494868</td>\n",
       "      <td>0.508245</td>\n",
       "      <td>0.498493</td>\n",
       "      <td>0.360903</td>\n",
       "      <td>0.440779</td>\n",
       "      <td>0.435120</td>\n",
       "      <td>0.479331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 vs 4</th>\n",
       "      <td>0.518357</td>\n",
       "      <td>0.487315</td>\n",
       "      <td>0.630019</td>\n",
       "      <td>0.477721</td>\n",
       "      <td>0.451976</td>\n",
       "      <td>0.395134</td>\n",
       "      <td>0.387644</td>\n",
       "      <td>0.430077</td>\n",
       "      <td>0.465813</td>\n",
       "      <td>0.526334</td>\n",
       "      <td>0.465223</td>\n",
       "      <td>0.351253</td>\n",
       "      <td>0.429015</td>\n",
       "      <td>0.307560</td>\n",
       "      <td>0.451674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 vs 4</th>\n",
       "      <td>0.531080</td>\n",
       "      <td>0.463552</td>\n",
       "      <td>0.630873</td>\n",
       "      <td>0.486086</td>\n",
       "      <td>0.466264</td>\n",
       "      <td>0.442209</td>\n",
       "      <td>0.392922</td>\n",
       "      <td>0.486439</td>\n",
       "      <td>0.468347</td>\n",
       "      <td>0.511459</td>\n",
       "      <td>0.471424</td>\n",
       "      <td>0.369784</td>\n",
       "      <td>0.432927</td>\n",
       "      <td>0.335330</td>\n",
       "      <td>0.463478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.523359</td>\n",
       "      <td>0.468389</td>\n",
       "      <td>0.617771</td>\n",
       "      <td>0.474881</td>\n",
       "      <td>0.486057</td>\n",
       "      <td>0.430549</td>\n",
       "      <td>0.388642</td>\n",
       "      <td>0.471289</td>\n",
       "      <td>0.465151</td>\n",
       "      <td>0.492126</td>\n",
       "      <td>0.475331</td>\n",
       "      <td>0.347191</td>\n",
       "      <td>0.435164</td>\n",
       "      <td>0.374349</td>\n",
       "      <td>0.460732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "0 vs 1  0.519554  0.462886  0.595989  0.455916  0.508987  0.437295  0.385088   \n",
       "0 vs 2  0.517262  0.466954  0.614793  0.505941  0.482850  0.418632  0.360367   \n",
       "0 vs 3  0.529353  0.465469  0.615186  0.488525  0.510776  0.451548  0.380558   \n",
       "0 vs 4  0.501555  0.461180  0.612255  0.477740  0.470529  0.403346  0.366094   \n",
       "1 vs 2  0.534864  0.496664  0.618571  0.477283  0.512987  0.435789  0.416289   \n",
       "1 vs 3  0.534862  0.459619  0.605366  0.457003  0.505878  0.478589  0.395858   \n",
       "1 vs 4  0.517859  0.428197  0.615715  0.431304  0.460887  0.390210  0.410461   \n",
       "2 vs 3  0.528846  0.492057  0.638946  0.491296  0.489440  0.452739  0.391141   \n",
       "2 vs 4  0.518357  0.487315  0.630019  0.477721  0.451976  0.395134  0.387644   \n",
       "3 vs 4  0.531080  0.463552  0.630873  0.486086  0.466264  0.442209  0.392922   \n",
       "Mean    0.523359  0.468389  0.617771  0.474881  0.486057  0.430549  0.388642   \n",
       "\n",
       "               7         8         9        10        11        12        13  \\\n",
       "0 vs 1  0.478070  0.458332  0.464174  0.491516  0.332827  0.437981  0.405140   \n",
       "0 vs 2  0.455240  0.448881  0.494417  0.486628  0.301431  0.418792  0.363073   \n",
       "0 vs 3  0.511770  0.471389  0.476813  0.471540  0.359428  0.444039  0.377355   \n",
       "0 vs 4  0.460177  0.436334  0.485916  0.458933  0.343896  0.442039  0.277360   \n",
       "1 vs 2  0.460714  0.480073  0.489167  0.483012  0.351819  0.434470  0.449716   \n",
       "1 vs 3  0.492306  0.475342  0.472882  0.469717  0.356553  0.433657  0.487613   \n",
       "1 vs 4  0.450347  0.452135  0.491847  0.456821  0.344011  0.437947  0.305222   \n",
       "2 vs 3  0.487755  0.494868  0.508245  0.498493  0.360903  0.440779  0.435120   \n",
       "2 vs 4  0.430077  0.465813  0.526334  0.465223  0.351253  0.429015  0.307560   \n",
       "3 vs 4  0.486439  0.468347  0.511459  0.471424  0.369784  0.432927  0.335330   \n",
       "Mean    0.471289  0.465151  0.492126  0.475331  0.347191  0.435164  0.374349   \n",
       "\n",
       "            Mean  \n",
       "0 vs 1  0.459554  \n",
       "0 vs 2  0.452519  \n",
       "0 vs 3  0.468125  \n",
       "0 vs 4  0.442668  \n",
       "1 vs 2  0.474387  \n",
       "1 vs 3  0.473232  \n",
       "1 vs 4  0.442354  \n",
       "2 vs 3  0.479331  \n",
       "2 vs 4  0.451674  \n",
       "3 vs 4  0.463478  \n",
       "Mean    0.460732  "
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_correlation_table(data_directory):\n",
    "    out = pd.DataFrame(np.random.randn(1,14))\n",
    "    df = [pd.read_csv(os.path.join(data_directory, 'fold{}_test.csv'.format(i))) for i in range(5)]\n",
    "    \n",
    "    for i, _ in enumerate(df):\n",
    "        for j,_ in enumerate(df):\n",
    "            if i != j and j>i:\n",
    "                string = '{} vs {}'.format(i,j)\n",
    "                out.loc[string] = list(df[i].corrwith(df[j]))\n",
    "    out = out.drop([0], axis = 0)\n",
    "    out.loc['Mean'] = out.mean()\n",
    "    out['Mean'] = out.mean(axis=1)\n",
    "    out.to_csv(os.path.join(data_directory,'corr_of_models.csv'))\n",
    "    return out\n",
    "create_correlation_table('../dataset/outputs/inceptionV3_FocalLoss_40epochs')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv_kernel",
   "language": "python",
   "name": "myenv_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
